# -*- coding: utf-8 -*-
"""B20BB051_Lab_Project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1G02dflOsVIJ4wrMY1fMOPFV0Oj3wokBg
"""

!wget https://www.dropbox.com/s/lneohlcyhmir7ud/CovidDataset.zip
!unzip CovidDataset.zip

TRAIN_PATH = "CovidDataset/Train"
TEST_PATH = "CovidDataset/Test"

"""## Importing necessary libraries"""

import numpy as np
import matplotlib.pyplot as plt
from PIL import Image
import tensorflow.keras as keras
from tensorflow.keras.layers import *
from tensorflow.keras.models import *
from tensorflow.keras.preprocessing import image

img = Image.open('CovidDataset/Train/Covid/01E392EE-69F9-4E33-BFCE-E5C968654078.jpeg')
plt.title("Covid +ve")
plt.imshow(img)
plt.plot()

img = Image.open('CovidDataset/Train/Normal/IM-0156-0001.jpeg')
plt.title("Covid -ve")
plt.imshow(img)
plt.plot()

"""## Defining my CNN Model"""

model = Sequential()
model.add(Conv2D(32, kernel_size=(3, 3),
                 activation='relu',
                 input_shape=(224,224,3)))
model.add(Conv2D(64, (3, 3), activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.25))
model.add(Conv2D(64, (3, 3), activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.25))
model.add(Conv2D(128, (3, 3), activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.25))
model.add(Flatten())
model.add(Dense(64, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(1, activation='sigmoid'))

model.compile(loss=keras.losses.binary_crossentropy,
              optimizer='adam',
              metrics=['accuracy'])

keras.utils.plot_model(
    model, to_file='model.png', show_shapes=True, show_layer_names=True,
    rankdir='TB', expand_nested=False, dpi=96
)

model.summary()

"""## Making Data ready for our designed model"""

train_datagen = image.ImageDataGenerator(
        rescale=1./255,
        shear_range=0.2,
        zoom_range=0.2,
        horizontal_flip=True)

test_datagen = image.ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_directory(
        'CovidDataset/Train',
        target_size=(224, 224),
        batch_size=32,
        class_mode='binary')

validation_generator = test_datagen.flow_from_directory(
        'CovidDataset/Val',
        target_size=(224, 224),
        batch_size=32,
        class_mode='binary')

224//32

"""## Training the model"""

hist = model.fit_generator(
        train_generator,
        steps_per_epoch=7,
        epochs=10,
        validation_data=validation_generator,
        validation_steps=2)

"""## Saving the trained model to use as a web app"""

model.save("model_adv.h5")

!pip install tensorflowjs

import tensorflowjs as tfjs

tfjs.converters.save_keras_model(model,'/content/CovidDataset')

model.evaluate_generator(train_generator)

model.evaluate_generator(validation_generator)

"""## Testing my model"""

model = load_model('model_adv.h5')

import os

import tensorflow as tf
tf.__version__

train_generator.class_indices

y_actual = []
y_test = []

for i in os.listdir("./CovidDataset/Val/Normal/"):
    img = image.load_img("./CovidDataset/Val/Normal/"+i, target_size=(224,224))
    img = image.img_to_array(img)
    img = np.expand_dims(img, axis=0)
    preds = model.predict(img)
    predicted_class = np.argmax(preds)
    y_test.append(predicted_class)
    y_actual.append(1)

for i in os.listdir("./CovidDataset/Val/Covid/"):
    img = image.load_img("./CovidDataset/Val/Covid/"+i, target_size=(224,224))
    img = image.img_to_array(img)
    img = np.expand_dims(img, axis=0)
    preds = model.predict(img)
    predicted_class = np.argmax(preds)
    y_test.append(predicted_class)
    y_actual.append(0)

y_actual = np.array(y_actual)
y_test = np.array(y_test)

print("Total: ",len(y_test))
print("Predictions: ", y_test)

print("Total: ",len(y_actual))
print("Predictions: ", y_actual)

f, axarr = plt.subplots(2,1)
axarr[0].plot(y_actual, marker='d', color='blue', drawstyle='steps-pre')
axarr[1].plot(y_test, marker='d', color='blue', drawstyle='steps-pre')
plt.show()

"""## Generating Confusion Matrix"""

from sklearn.metrics import confusion_matrix

cm = confusion_matrix(y_actual, y_test)

"""## Testing purposes"""

import seaborn as sns

#sns.heatmap(cm, cmap="plasma", annot=True)

"""## Using ImgAug"""

import os
import numpy as np
import matplotlib.pyplot as plt
import keras
from keras.layers import *
from keras.models import *
from keras.preprocessing import image
from tensorflow.keras.preprocessing import image

X_train = []
y_train = []

imgs = os.listdir("CovidDataset/Train/Covid/")

for i in imgs:
    i = image.load_img("CovidDataset/Train/Covid/"+i , target_size=(224,224,3))
    i = image.img_to_array(i)/255.
    X_train.append(i)
    y_train.append(0)

imgs = os.listdir("CovidDataset/Train/Normal/")

for i in imgs:
    i = image.load_img("CovidDataset/Train/Normal/"+i , target_size=(224,224,3))
    i = image.img_to_array(i)/255.
    X_train.append(i)
    y_train.append(1)

X_train = np.array(X_train)
y_train = np.array(y_train)

X_train.shape

y_train.shape

from imgaug import augmenters as iaa
import imgaug as ia
import imgaug.augmenters as iaa

seq = iaa.Sequential([
    iaa.Fliplr(0.5), # horizontal flips
    iaa.Crop(percent=(0, 0.1)), # random crops
    
    # Small gaussian blur with random sigma between 0 and 0.5.
    # But we only blur about 50% of all images.
    iaa.Sometimes(
        0.5,
        iaa.GaussianBlur(sigma=(0, 0.3))
    ),
    
    # Strengthen or weaken the contrast in each image.
    iaa.LinearContrast((0.75, 1.2)),
    
    # Add gaussian noise.
    # For 50% of all images, we sample the noise once per pixel.
    # For the other 50% of all images, we sample the noise per pixel AND
    # channel. This can change the color (not only brightness) of the
    # pixels.
    
    iaa.AdditiveGaussianNoise(loc=0, scale=(0.0, 0.02), per_channel=0.5),
    
    # Make some images brighter and some darker.
    # In 30% of all cases, we sample the multiplier once per channel,
    # which can end up changing the color of the images.
    iaa.Multiply((0.8, 1.1), per_channel=0.3),
    
    # Apply affine transformations to each image.
    # Scale/zoom them, translate/move them, rotate them and shear them.

#     iaa.Affine(
#         scale={"x": (0.8, 1.2), "y": (0.8, 1.2)}
#     )
    
], random_order=True) # apply augmenters in random order

images_aug = seq(images=X_train)

for im in images_aug[:10]:
    plt.imshow(im)
    plt.show()

import random

combined = list(zip(images_aug,y_train))
random.shuffle(combined)

#Unzip
images_aug[:],y_train[:] = zip(*combined)

images_aug.shape

y_train.shape

model = Sequential()
model.add(Conv2D(32, kernel_size=(3, 3),
                 activation='relu',
                 input_shape=(224,224,3)))
model.add(Conv2D(64, (3, 3), activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.25))
model.add(Conv2D(64, (3, 3), activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.25))
model.add(Conv2D(128, (3, 3), activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.25))
model.add(Flatten())
model.add(Dense(64, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(1, activation='sigmoid'))

model.compile(loss=keras.losses.binary_crossentropy,
              optimizer='adam',
              metrics=['accuracy'])

model.summary()

X_test = []
y_test = []

imgs = os.listdir("CovidDataset/Val/Covid/")
for i in imgs:
    i = image.load_img("CovidDataset/Val/Covid/"+i , target_size=(224,224,3))
    i = image.img_to_array(i)/255.
    X_test.append(i)
    y_test.append(0)
    
imgs = os.listdir("CovidDataset/Val/Normal/")
for i in imgs:
    i = image.load_img("CovidDataset/Val/Normal/"+i , target_size=(224,224,3))
    i = image.img_to_array(i)/255.
    X_test.append(i)
    y_test.append(1)
    
    
X_test = np.array(X_test)
y_test = np.array(y_test)

combined = list(zip(X_test,y_test))
random.shuffle(combined)

#Unzip
X_test[:],y_test[:] = zip(*combined)

hist = model.fit(
        images_aug,
        y_train,
        batch_size=32,
        epochs=10,
        validation_data = (X_test, y_test))

"""### 10 more epochs"""
hist = model.fit(
        images_aug,
        y_train,
        batch_size=32,
        epochs=10,
        validation_data = (X_test, y_test))